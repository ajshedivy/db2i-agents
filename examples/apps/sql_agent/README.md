# SQrL: A Text2SQL Reasoning Agent

SQrL is an advanced text-to-SQL system that leverages Reasoning Agents to provide deep insights into any data. The system works with IBM Db2 for i sample dataset, which contains enterprise data including employee information, department structure, project management, and business operations.

The agent uses Reasoning Agents to search for table metadata and rules, enabling it to write and run better SQL queries. This process, called `Dynamic Few Shot Prompting`, is a technique that allows the agent to dynamically search for few shot examples to improve its performance.

SQrL also "thinks" before it acts. It will think about the user's question, and then decide to search its knowledge base before writing and running the SQL query.

SQrL also "analyzes" the result of the SQL query, which yield much better results.

> Note: Fork and clone the repository if needed

### 1. Install dependencies

Install the dependencies:

- uv:  
    ```bash
    curl -LsSf https://astral.sh/uv/install.sh | sh
    ```

- Install Ollama from [Ollama](https://ollama.com/)
- Pull Ollama models:
    ```bash
    ollama pull qwen3:8b

    # model used for embeddings
    ollama pull openhermes
    ```

The `uv run` command automatically creates a virtual environment and manages dependencies.

---

### 2. Load the knowledge base

The knowledge base contains table metadata, rules and sample queries, which are used by the Agent to improve responses. This data is stored in the `knowledge/` folder and is used by the Agent at run-time to search for sample queries and rules.

The following command creates embeddings for the knowledge base and stores them in a vector database. The knowledge base is stored in the `tmp/lancedb` directory.

```shell
# Basic usage - loads knowledge from knowledge/sample directory
uv run load_knowledge.py

# With options to specify directory and recreate knowledge
# uv run load_knowledge.py --destination knowledge/sample --recreate
```

Available options for load_knowledge.py:
- `--destination` or `-d`: Directory path where description files will be saved (default: knowledge/sample)
- `--recreate`: Overwrite existing files if destination directory already exists
- `--no-load`: Skip loading knowledge into agent (default: False, knowledge is loaded)

We recommend adding the following to enhance the agent's capabilities:
  - Add `table_rules` and `column_rules` to the table metadata. The Agent is prompted to follow them. This is useful when you want to guide the Agent to always query date in a particular format, or avoid certain columns.
  - Add sample SQL queries to the `knowledge/sample_queries.sql` file. This will give the Assistant a head start on how to write complex queries.

### 3. Storage and Persistence

The application uses SQLite for storage, configured in the agents.py file:

```python
# Database connection configuration
db_url = "tmp/agent_data.db"

# SQLite storage for agent sessions
agent_storage = SqliteStorage(
    table_name="sql_agent_sessions",
    db_file=db_url,
    auto_upgrade_schema=True,
)
```

This SQLite database stores:
- Agent conversations and history
- Session information
- Tool call history

The knowledge base is stored using LanceDb in the tmp/lancedb directory for vector search capabilities.

### 4. Export API Keys

We recommend using claude-3-7-sonnet for this task, but you can use any Model you like.

```shell
export ANTHROPIC_API_KEY=***
```

Other API keys are optional, but if you'd like to test:

```shell
export OPENAI_API_KEY=***
export GOOGLE_API_KEY=***
export GROQ_API_KEY=***
```

### 5. Run SQL Agent

```shell
# Start the Streamlit app using uv run
uv run streamlit run app.py
```

The app lets you:
- Select different language models (OpenAI, Anthropic, Google, etc.)
- Ask natural language questions about the IBM Db2i sample dataset
- View SQL queries generated by the agent
- See query results and analysis

- Open [localhost:8501](http://localhost:8501) to view the SQL Agent.

### 6. Message us on [discord](https://agno.link/discord) if you have any questions

